# FAMO TrafficApp 3.0

On-Prem Routenplanung mit KI fÃ¼r die FAMO GmbH. Dieses System ermÃ¶glicht die Verarbeitung von Tourplan-CSVs mit automatischer Geocodierung und Adresserkennung.

---

## ğŸ“˜ **NEU: Zentrale Dokumentation**

### ğŸŒ **Globale Standards (projektÃ¼bergreifend)**

**FÃ¼r alle Cursor-Projekte:**
- â†’ [`Global/GLOBAL_STANDARDS.md`](Global/GLOBAL_STANDARDS.md) - Universelle Entwicklungs-Standards
- â†’ [`Global/PROJEKT_TEMPLATE.md`](Global/PROJEKT_TEMPLATE.md) - Quick-Start fÃ¼r neue Projekte

### ğŸ“‹ **Projektprofil (FAMO TrafficApp)**

**Technischer Ãœberblick fÃ¼r dieses Projekt:**
- â†’ [`PROJECT_PROFILE.md`](PROJECT_PROFILE.md) - Stack, Infrastruktur, Module, Teststrategie

### ğŸ“˜ **Projekt-Regeln & Standards**

**Projektspezifische Standards:**
- â†’ [`Regeln/`](Regeln/) - 8 Kern-Dokumente (STANDARDS.md, AUDIT_CHECKLISTE.md, etc.)

**Siehe auch:** [`REGELN_HIER.md`](REGELN_HIER.md) fÃ¼r Schnellzugriff

---

## ğŸ“‹ Neue Features

### Adaptive Pattern Engine (Kostenlos & Selbstlernend)

**Problem gelÃ¶st:** AI-Kosten vs. statischer Python-Code

**LÃ¶sung:** Selbstlernendes System, das Pattern automatisch erkennt und speichert - ohne API-Kosten.

**Details:** Siehe `docs/FA_DOKUMENTATION_ADAPTIVE_PATTERN_ENGINE.md`

**Vorteile:**
- âœ… 100% kostenlos (keine API-Aufrufe)
- âœ… 100-500x schneller als AI (1ms vs. 500ms)
- âœ… Selbstlernend (keine manuelle Pflege)
- âœ… Deterministisch (immer gleiches Ergebnis)

**Ersparnis:** $30-300/Monat (je nach Nutzung)

## ğŸ“Š Projektstatus

**Aktueller Stand:** ~80-85% abgeschlossen

âœ… **Fertiggestellt:**
- CSV-Parsing mit Synonym-Integration
- DB-First Geocoding (Geoapify, Mapbox, Nominatim)
- Tour-Optimierung (LLM + Nearest-Neighbor)
- Sub-Routen Generator fÃ¼r groÃŸe Touren
- Automatische DB-Backups
- Test Dashboard

ğŸš§ **In Arbeit:**
- UI-AufrÃ¤umarbeiten (nÃ¤chste Woche)
- Reasoning-Feld in UI integrieren
- Cloud-Synchronisation
- AI-Integration finalisieren

**Details:** Siehe `docs/PROJECT_STATUS.md`

---

## ğŸ¤– FÃ¼r Cursor-KI: Code-Audits

### **Standard-Workflow fÃ¼r Bug-Fixes:**

**â­ Lies zuerst:** [`Regeln/CURSOR_WORKFLOW.md`](Regeln/CURSOR_WORKFLOW.md) â†’ **Kompletter 6-Schritt-Prozess!**

1. **Problem klarziehen** (Beschreibung + Logs + Screenshots)
2. **Audit-ZIP vorbereiten** (relevante Dateien + README)
3. **Template wÃ¤hlen** (CURSOR_PROMPT_TEMPLATE.md â†’ #1 oder #10)
4. **Ã„nderung einbauen** (nur wenn verstÃ¤ndlich + standards-konform)
5. **Tests & Health-Checks** (Server starten + manuell testen)
6. **Lessons aktualisieren** (LESSONS_LOG + REGELN bei neuem Pattern)

**Wichtige Regeln:**
- âš ï¸ **Multi-Layer-Pflicht:** Backend + Frontend + DB + Infra
- âŒ **Kein Ghost-Refactoring:** Nur explizit genannte Dateien
- âœ… **Tests schreiben:** Min. 1 Regressionstest pro Fix
- ğŸ¥ **Health-Checks:** Vor Abschluss prÃ¼fen
- ğŸ“ **Dokumentieren:** LESSONS_LOG aktualisieren

### **Quick-Links:**
- ğŸ”„ [6-Schritt-Workflow](Regeln/CURSOR_WORKFLOW.md) â­ **NEU!**
- ğŸ“– [VollstÃ¤ndige Standards](Regeln/STANDARDS.md)
- ğŸš€ [Schnellreferenz](Regeln/STANDARDS_QUICK_REFERENCE.md)
- ğŸ¤– [12 Cursor-Templates](Regeln/CURSOR_PROMPT_TEMPLATE.md)

---

## ğŸš€ Schnellstart

### Setup in 60 Sekunden

1. **Umgebungsvariablen einrichten**
   ```bash
   cp env.example .env
   # Optional: DATABASE_URL anpassen
   ```

2. **Original-CSV-Dateien ablegen**
   ```bash
   # Kopiere deine CSV-Dateien nach ./Tourplaene/
   # Diese werden NICHT verÃ¤ndert (read-only)
   ```

3. **AbhÃ¤ngigkeiten installieren**
   ```bash
   pip install -r requirements.txt
   ```

4. **Pre-commit optional**
   ```bash
   pip install pre-commit && pre-commit install
   ```

5. **Starten & prÃ¼fen**
   ```bash
   # IntegritÃ¤t der Original-CSVs prÃ¼fen
   python -m tools.orig_integrity build
   
   # App starten
   python backend/app.py
   
   # Health-Check
   curl http://127.0.0.1:8111/health/db
   # Sollte {"ok": true} zurÃ¼ckgeben
   
   # CSV-Liste prÃ¼fen
   curl http://127.0.0.1:8111/api/tourplaene/list
   # Sollte verfÃ¼gbare CSVs anzeigen
   
   # App Ã¶ffnen
   # http://127.0.0.1:8111
   ```

### Smoke-Test (lokal)

Backend starten, dann:
```bash
python -m tools.smoke
```

**Erwartet:**
- âœ” list (mind. eine CSV)
- âœ” match (zeigt ok/warn/bad Summen)
- âœ” geofill dry (HTTP 200)
- âœ” status (ZÃ¤hler sichtbar)

### Docker-Entwicklung

1. **Mit Docker Compose**
   ```bash
   docker-compose up --build
   ```

2. **App Ã¶ffnen**
   ```
   http://localhost:8111
   ```

## ğŸ”„ Git-Synchronisation

FÃ¼r automatische Git-Synchronisation stehen Scripts zur VerfÃ¼gung:

### PowerShell (Empfohlen)
```powershell
.\scripts\git_sync.ps1 "Commit-Nachricht"
```

### Batch (Windows)
```batch
scripts\git_sync.bat "Commit-Nachricht"
```

Die Scripts fÃ¼hren automatisch aus:
- âœ… `git add .` (alle Ã„nderungen)
- âœ… `git commit` (mit Zeitstempel)
- âœ… `git push` (zu Remote-Repository)

**Hinweis:** Bei erstmaliger Verwendung muss ein Remote-Repository konfiguriert werden:
```bash
git remote add origin <URL>
git push -u origin main
```

## ğŸ“ Projektstruktur

```
TrafficApp/
â”œâ”€â”€ backend/           # FastAPI Backend
â”œâ”€â”€ frontend/          # HTML/CSS/JS Frontend
â”œâ”€â”€ data/              # Daten-Verzeichnisse
â”‚   â”œâ”€â”€ staging/       # Staging-Bereich
â”‚   â””â”€â”€ output/        # Ausgabe-Verzeichnis
â”œâ”€â”€ Tourplaene/        # Original-CSVs (read-only)
â”œâ”€â”€ routen/            # Backup-Verzeichnis
â”œâ”€â”€ scripts/           # Hilfsskripte
â”‚   â””â”€â”€ hooks/         # Pre-commit-Hooks
â”œâ”€â”€ tests/             # Unit-Tests
â””â”€â”€ docs/              # Dokumentation
```

## ğŸ“‹ PF/BAR-Synonyme

PF-Kunden (â€Jochen â€“ PF", â€Sven â€“ PF") werden **nicht** geocodiert, sondern aus Synonym-Stammdaten bedient.

### Funktionsweise

- **Synonym-Resolver**: `common/synonyms.py` enthÃ¤lt feste Koordinaten fÃ¼r PF-Kunden
- **Short-Circuit**: Geocoder wird fÃ¼r PF-Kunden **nicht** aufgerufen
- **Frontend**: Zeigt `resolved_address`, routet via `lat/lon`
- **Audit**: ZÃ¤hlt Synonyme als geokodiert

### Synonym-Koordinaten pflegen

```python
# In common/synonyms.py
_SYNONYMS: Dict[str, SynonymHit] = {
    "PF:JOCHEN": SynonymHit("PF:JOCHEN", "Pf-Depot Jochen, Dresden", 51.0500, 13.7373),
    "PF:SVEN":   SynonymHit("PF:SVEN",   "Pf-Depot Sven, Dresden",   51.0600, 13.7300),
}
```

### Akzeptanzkriterien

- âœ… â€Jochen â€“ PF" und â€Sven â€“ PF" erscheinen **mit Koordinaten** und **ohne** â€nan, nan nan"
- âœ… Geocoder wird fÃ¼r diese EintrÃ¤ge **nicht** angerufen (Short-Circuit)
- âœ… API liefert DTO mit `resolved_address`, `geo_source='synonym'`, `valid=true`
- âœ… Audit: `missing_count == 0` bei CSV mit nur PF-EintrÃ¤gen

### Kundennummern-Resolver (neu)

- In `common/synonyms.py` ist ein schlanker Resolver hinterlegt: `resolve_customer_number(name) -> Optional[int]`.
- Zweck: FÃ¼r Synonyme die echte ERP-Kundennummer verfÃ¼gbar machen, ohne bestehende CSV-Felder zu Ã¼berschreiben.
- API/DTO-Nutzung: wird als separates Feld `customer_number_resolved` ausgegeben (nicht verpflichtend im UI).

### CSV/Import-HÃ¤rtung (NaN/Excel-Apostroph)

- Parser und Bulk-Prozessor entfernen fÃ¼hrende/abschlieÃŸende Apostrophâ€‘Marker aus Excel und wandeln `NaN` in leere Strings um.
- Adressen werden nur aus vorhandenen Teilen gebaut; es erscheint kein â€nan, nan nanâ€œ oder ", ," mehr.
- Frontend rendert priorisiert `resolved_address`, danach `address`, sonst aus Teilen `street, postal_code, city` (bereinigt).

## ğŸ›¡ï¸ SchutzmaÃŸnahmen

### Pre-commit-Hooks

Das System verwendet Pre-commit-Hooks zum Schutz der Original-CSVs:

- **Blockiert Schreibzugriffe** auf `./Tourplaene/`
- **Scannt verdÃ¤chtige Muster** in Code-Ã„nderungen
- **Verhindert versehentliche Modifikationen** der Original-Dateien

### Docker Read-Only-Mounts

Bei Docker-Deployment werden Original-Verzeichnisse read-only gemountet:

```yaml
volumes:
  - ./Tourplaene:/app/Tourplaene:ro    # Originale nur lesen
  - ./data:/app/data:rw                # Daten beschreibbar
```

### CI/CD-Pipeline

GitHub Actions fÃ¼hrt automatisch aus:

- **IntegritÃ¤tsprÃ¼fungen** der Original-Dateien
- **Unit-Tests** aller Komponenten
- **Docker-Build-Tests**
- **Pre-commit-Hook-Validierung**

## ğŸ”§ Konfiguration

### Umgebungsvariablen

Erstelle eine `.env`-Datei:

```env
# Verzeichnisse
ORIG_DIR=./Tourplaene
STAGING_DIR=./data/staging
OUTPUT_DIR=./data/output
BACKUP_DIR=./routen

# Datenbank
DATABASE_URL=sqlite:///data/traffic.db

# Geocoding
GEOCODER_BASE=https://nominatim.openstreetmap.org/search
GEOCODER_CONTACT=your-email@example.com
GEOCODER_RPS=1
GEOCODER_TIMEOUT_S=20
```

## ğŸ§ª Tests

```bash
# Alle Tests ausfÃ¼hren
pytest

# Tests mit Coverage
pytest --cov=backend --cov=repositories --cov=services

# Spezifische Tests
pytest tests/test_geocode_robust_simple.py -v
```

## ğŸ“Š API-Endpoints

- `GET /api/tourplaene/list` - Liste verfÃ¼gbarer CSVs
- `GET /api/tourplan/match` - Adressen gegen Cache matchen
- `GET /api/tourplan/geocode-missing` - Fehlende Adressen geokodieren
- `GET /api/tourplan/status` - Status-ZÃ¤hler fÃ¼r CSV
- `GET /health/db` - Datenbank-Health-Check
- `GET /audit/orig-integrity` - Original-IntegritÃ¤tsprÃ¼fung

## ğŸ”’ Sicherheitsfeatures

- **PathPolicy**: Verhindert Schreibzugriffe auf Original-Verzeichnisse
- **Fail-Cache**: Verhindert wiederholte Anfragen problematischer Adressen
- **Retry/Backoff**: Robuste Behandlung von Rate-Limiting und Timeouts
- **IntegritÃ¤tsprÃ¼fung**: SHA256-Hashes fÃ¼r Original-CSVs
- **Pre-commit-Hooks**: Lokaler Schutz vor versehentlichen Ã„nderungen

## ğŸ“ Entwicklung

### Pre-commit-Hooks aktivieren

```bash
pip install pre-commit
pre-commit install
```

### Tests ausfÃ¼hren

```bash
pytest -v
```

### Docker-Tests

```bash
docker build -t trafficapp-test .
docker-compose config
```

## ğŸš¨ Wichtige Hinweise

- **`./Tourplaene/` ist schreibgeschÃ¼tzt** - Verwende `./data/staging/` oder `./data/output/` fÃ¼r Ausgaben
- **Original-CSVs dÃ¼rfen nie modifiziert werden** - Pre-commit-Hooks verhindern dies
- **Docker mountet Originale read-only** - Nur Daten-Verzeichnisse sind beschreibbar
- **CI/CD prÃ¼ft IntegritÃ¤t** - Automatische Validierung bei jedem Push/PR

## ğŸ“ Support

Bei Problemen oder Fragen:

1. PrÃ¼fe die Logs in `./logs/`
2. FÃ¼hre `pytest` aus, um Tests zu validieren
3. PrÃ¼fe die CI/CD-Pipeline auf GitHub Actions
4. Kontaktiere das Entwicklungsteam

## Routing Health Checks & Testing

Um die StabilitÃ¤t und VerfÃ¼gbarkeit des Routings zu Ã¼berprÃ¼fen, kÃ¶nnen Sie die folgenden Endpunkte und Skripte verwenden:

* **`GET /health/osrm`**: ÃœberprÃ¼ft den Status des OSRM-Dienstes, einschlieÃŸlich Circuit Breaker und Fallback-Status.
* **`GET /_debug/routes`**: Listet alle registrierten API-Routen auf, nÃ¼tzlich zur Verifizierung der Router-Registrierung.
* **Smoke-Test Skript (`scripts/test_smoke_routing.py`)**:
  Dieses Skript sendet Testanfragen an den `/api/tour/route-details`-Endpunkt, um die grundlegende FunktionalitÃ¤t und Fehlerbehandlung zu verifizieren. FÃ¼hren Sie es mit `python scripts/test_smoke_routing.py` aus.

```bash
python scripts/test_smoke_routing.py
```
