# âš¡ PERFORMANCE-ANALYSE

**Datum:** 2025-11-13  
**Umfang:** Backend-Codebase (Routes, Services, Utils)  
**Fokus:** Bottlenecks, ineffiziente Queries, Memory-Leaks

---

## ğŸ“Š EXECUTIVE SUMMARY

### Performance-Score: **6/10** (Verbesserungspotenzial vorhanden)

**Hauptprobleme:**
- ğŸ”´ `workflow_api.py`: 2568 Zeilen (Monolith-File)
- ğŸŸ¡ Nested Loops in `optimize_tour_with_ai`
- ğŸŸ¡ Blocking `time.sleep()` in async context
- ğŸŸ¡ Keine Caching-Strategy fÃ¼r hÃ¤ufige Queries

**Positiv:**
- âœ… Database Connection-Pooling (SQLAlchemy)
- âœ… Async/Await fÃ¼r I/O-Operations
- âœ… Circuit-Breaker fÃ¼r externe Services

---

## ğŸ” DETAILLIERTE FINDINGS

### ğŸ”´ CRITICAL: workflow_api.py ist zu groÃŸ (2568 Zeilen)

**Datei:** `backend/routes/workflow_api.py`  
**Problem:** MONOLITH-FILE  
**Impact:** 
- Schwer zu warten
- Lange Compile-Zeit
- Merge-Konflikte wahrscheinlich
- Schwierige Code-Navigation

**Empfohlene Refactoring-Strategie:**

```
backend/routes/
â”œâ”€â”€ workflow_api.py (200 Zeilen - nur Router-Registration)
â”œâ”€â”€ workflow/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ upload.py (File-Upload-Logic)
â”‚   â”œâ”€â”€ optimize.py (Tour-Optimization)
â”‚   â”œâ”€â”€ classify.py (AI-Classification)
â”‚   â”œâ”€â”€ group.py (Tour-Grouping)
â”‚   â””â”€â”€ helpers.py (Shared utilities)
```

**Aufwand:** 8-12 Stunden  
**PrioritÃ¤t:** ğŸ”´ HOCH (Maintainability)

---

### ğŸŸ¡ MEDIUM: Blocking time.sleep() in Async Context

**Dateien gefunden:**
- `backend/routes/workflow_api.py`
- `backend/routes/tourplan_geofill.py`
- `backend/services/geocode.py`

**Problem:**
```python
# âŒ BLOCKING in async function
async def some_function():
    time.sleep(1.0)  # Blockiert gesamten Event-Loop!
```

**Warum ist das ein Problem?**
- `time.sleep()` blockiert den gesamten Event-Loop
- Alle anderen Requests mÃ¼ssen warten
- Performance-Degradation unter Last

**Richtig:**
```python
# âœ… Non-blocking
import asyncio

async def some_function():
    await asyncio.sleep(1.0)  # Gibt Event-Loop frei
```

**Gefundene Stellen:**
1. `workflow_api.py:1179, 1197` - File-Handle-Wait (0.2s)
2. `workflow_api.py:1480` - Cleanup-Retry (0.2s)
3. `tourplan_geofill.py:115` - Rate-Limiting (1.0s)

**Fix:**
```python
# VORHER:
time.sleep(0.2)

# NACHHER:
await asyncio.sleep(0.2)
```

**Aufwand:** 1-2 Stunden  
**PrioritÃ¤t:** ğŸŸ¡ MITTEL

---

### ğŸŸ¡ MEDIUM: Nested Loops in Tour-Optimization

**Datei:** `backend/routes/workflow_api.py`  
**Funktion:** `optimize_tour_with_ai` (und Helfer)  
**GeschÃ¤tzter Count:** 47 nested loops

**Problem:**
Viele nested loops â†’ O(nÂ²) oder O(nÂ³) KomplexitÃ¤t

**Kritische Stellen:**
1. Sub-Tour-Splitting-Logic
2. Time-Calculation fÃ¼r Stops
3. Koordinaten-Validierung

**Beispiel (schematisch):**
```python
for tour in tours:  # O(n)
    for stop in tour['stops']:  # O(m)
        for validation in validations:  # O(k)
            # ... â†’ O(n*m*k)
```

**Empfohlene Optimierungen:**
1. **Batch-Processing:** Gruppiere Ã¤hnliche Operations
2. **Caching:** Wiederholte Berechnungen cachen
3. **Vectorization:** NumPy fÃ¼r numerische Operations
4. **Early-Exit:** Breche ab wenn Bedingung erfÃ¼llt

**Aufwand:** 4-6 Stunden (pro kritischer Stelle)  
**PrioritÃ¤t:** ğŸŸ¡ MITTEL

---

### ğŸŸ¡ LOW: Keine Caching-Strategy fÃ¼r hÃ¤ufige Queries

**Problem:**
Keine explizite Caching-Layer fÃ¼r:
- System-Rules (werden bei jedem Request neu geladen)
- Geocoding-Results (nur DB-Cache, kein In-Memory)
- OSRM-Routes (keine Cache-Strategy)

**Empfohlene LÃ¶sung:**
```python
from functools import lru_cache
from datetime import datetime, timedelta

# 1. In-Memory-Cache fÃ¼r System-Rules
@lru_cache(maxsize=1)
def get_cached_system_rules(cache_key: str):
    return load_system_rules()

def get_system_rules_with_ttl():
    # Cache-Key Ã¤ndert sich alle 5 Minuten
    cache_key = datetime.now().strftime("%Y-%m-%d-%H-%M")[:-1]  # Runde auf 10 Min
    return get_cached_system_rules(cache_key)

# 2. Redis-Cache fÃ¼r Geocoding (Optional)
import redis
redis_client = redis.Redis(host='localhost', port=6379)

def geocode_with_cache(address: str):
    # PrÃ¼fe Redis-Cache
    cached = redis_client.get(f"geo:{address}")
    if cached:
        return json.loads(cached)
    
    # Geocode und cache
    result = geocode_address(address)
    redis_client.setex(f"geo:{address}", 86400, json.dumps(result))  # 24h TTL
    return result
```

**Aufwand:** 3-4 Stunden  
**PrioritÃ¤t:** ğŸŸ¢ NIEDRIG (Nice-to-have)

---

### ğŸŸ¢ LOW: File-Logger schreibt synchron

**Datei:** `backend/utils/file_logger.py`  
**Zeilen:** 30-34

**Problem:**
```python
with open(LOG_FILE, "a", encoding="utf-8", errors="replace") as f:
    safe_message = message.encode('utf-8', errors='replace').decode('utf-8', errors='replace')
    f.write(f"[{timestamp}] {safe_message}\n")
    f.flush()  # Synchrones I/O
```

**Warum ist das ein Problem?**
- Synchrones Disk-I/O blockiert kurzzeitig
- Bei vielen Logs: Performance-Impact

**Impact:** Niedrig (wenige ms pro Log)

**Empfohlene LÃ¶sung (Optional):**
```python
import aiofiles

async def log_to_file_async(*args):
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-3]
    message = " ".join(str(arg) for arg in args)
    
    async with aiofiles.open(LOG_FILE, "a", encoding="utf-8") as f:
        await f.write(f"[{timestamp}] {message}\n")
        await f.flush()
```

**Aufwand:** 2-3 Stunden  
**PrioritÃ¤t:** ğŸŸ¢ NIEDRIG

---

## âœ… GOOD PRACTICES ERKANNT

### Performance-MaÃŸnahmen die GUT sind:

1. **âœ… Async/Await fÃ¼r I/O**
   - HTTPClient-Requests sind async
   - Database-Queries nutzen SQLAlchemy async (teilweise)

2. **âœ… Connection-Pooling**
   - SQLAlchemy ENGINE mit Connection-Pooling
   - Wiederverwendung von DB-Connections

3. **âœ… Circuit-Breaker fÃ¼r OSRM**
   - Verhindert Service-Overload
   - Schnelle Fehler-Erkennung

4. **âœ… Timeouts fÃ¼r externe Services**
   - OSRM: 3s/5s/10s (je nach Operation)
   - Geocoding: 20s
   - Verhindert Hanging-Requests

5. **âœ… Batch-Geocoding**
   - `_geocode_missing_new` verarbeitet mehrere Adressen
   - Rate-Limiting integriert

6. **âœ… Database-Indizes**
   - `db/schema.py` definiert Indizes fÃ¼r hÃ¤ufige Queries
   - Z.B. `idx_system_rules_audit_changed_at`

7. **âœ… Pagination fÃ¼r groÃŸe Resultsets**
   - `limit` Parameter in vielen Endpoints
   - Verhindert Memory-Overload

---

## ğŸ“‹ EMPFOHLENE OPTIMIERUNGEN (PRIORISIERT)

### Sofort (Diese Woche)
1. ğŸŸ¡ **Ersetze `time.sleep()` mit `asyncio.sleep()`** (1-2h)
2. ğŸŸ¢ **FÃ¼ge Logging-Level-Filter hinzu** (reduziere Debug-Logs in Produktion)

### Kurzfristig (NÃ¤chste 2 Wochen)
3. ğŸ”´ **Refactoring: workflow_api.py aufteilen** (8-12h)
4. ğŸŸ¡ **Optimiere nested loops in Tour-Optimization** (4-6h)

### Mittelfristig (NÃ¤chster Monat)
5. ğŸŸ¡ **Implementiere Caching-Layer (Redis)** (6-8h)
6. ğŸŸ¢ **Async File-Logging** (2-3h)
7. ğŸŸ¢ **Database-Query-Profiling** (Analyse langsamer Queries)

---

## ğŸ§ª PERFORMANCE-TESTS EMPFOHLEN

1. **Load-Testing:** `locust` oder `k6` fÃ¼r API-Endpoints
2. **Profiling:** `cProfile` fÃ¼r CPU-intensive Funktionen
3. **Memory-Profiling:** `memory_profiler` fÃ¼r Memory-Leaks
4. **Database-Profiling:** SQLAlchemy Query-Logging aktivieren

**Beispiel (Load-Test):**
```python
# locustfile.py
from locust import HttpUser, task, between

class TrafficAppUser(HttpUser):
    wait_time = between(1, 3)
    
    @task
    def optimize_tour(self):
        self.client.post("/api/tour/optimize", json={
            "tour_id": "test-tour",
            "stops": [...]  # Test-Daten
        })
    
    @task(2)  # 2x hÃ¤ufiger als optimize
    def health_check(self):
        self.client.get("/health/status")
```

AusfÃ¼hren:
```bash
locust -f locustfile.py --host=http://localhost:8111
```

---

## ğŸ“Š ZUSAMMENFASSUNG

### Performance-Bottlenecks

| Bottleneck | Impact | Aufwand | PrioritÃ¤t |
|------------|--------|---------|-----------|
| workflow_api.py GrÃ¶ÃŸe | HOCH | 8-12h | ğŸ”´ |
| Blocking sleep() | MITTEL | 1-2h | ğŸŸ¡ |
| Nested Loops | MITTEL | 4-6h | ğŸŸ¡ |
| Keine Caching-Strategy | NIEDRIG | 3-4h | ğŸŸ¢ |
| Sync File-Logging | NIEDRIG | 2-3h | ğŸŸ¢ |

### GeschÃ¤tzter Gesamt-Aufwand: 18-27 Stunden

### ROI-Bewertung
**MITTEL-HOCH:** Die grÃ¶ÃŸten Gains kommen von:
1. Refactoring (Maintainability)
2. Async-Fixes (Responsiveness unter Last)
3. Loop-Optimierungen (Skalierbarkeit)

---

**Erstellt:** 2025-11-13  
**Status:** Abgeschlossen  
**NÃ¤chste Schritte:** Implementierung der HochprioritÃ¤ts-Fixes

